head(Rain)
head(test$Rain)
head(test.df$Rain)
table(Rain)
nrows_prediction<-nrow(test.df)
prediction <- data.frame(c(1:nrows_prediction))
colnames(prediction) <- c("Rain")
str(prediction)
prediction$Rain <- as.character(prediction$Rain)
prediction$Rain <- "1"
prediction$Rain[ predicted_values < 0.5] <- "0"
prediction$Rain <- as.factor(prediction$Rain)
table(prediction$Rain, test.df$Rain)
length(prediction$Rain)
length(test.df$Rain)
test.Y = data1[-index,21]
table(prediction$Rain, test.Y)
confusionMatrix(factor(prediction$Rain,levels=min(test.Y):max(test.Y)),
factor(test.Y,levels=min(test.Y):max(test.Y)))
glm.diag.plots(model)
glm.diag.plots(model)
library(tidyverse)
library(boot)
library(forecast)
library(tseries)
library(caret)
library(ROCR)
library(corrplot)
library(psych)
# Data Input
data <- read.csv("C:/Users/Magilan/Desktop/ML_project/austin_weather.csv",header = TRUE)
data1=na.omit(data,invert=FALSE)
attach(data1)
summary(data1)
summary(Rain)
table(Rain)
windows()
mat=cor(data1[,-c(1,20)])
corrplot(mat,method = "square",order = "original")
windows()
pairs.panels(data1[,-c(1,20)],
gap=0,
pch = 21)
# Data Partitioning
index <- createDataPartition(Rain, p = 0.7, list = FALSE)
# Training set
train.df <- data1[index,]
# Testing dataset
test.df <- data1[-index,]
head(train.df)
head(test.df)
summary(train.df)
summary(test.df)
# Logistic regression
colnames(data1)
model <- glm(Rain ~ TempHighF+TempAvgF+TempLowF+DewPointHighF+DewPointAvgF+DewPointLowF+HumidityHighPercent+HumidityAvgPercent+HumidityLowPercent+SeaLevelPressureHighInches+SeaLevelPressureAvgInches+VisibilityLowMiles+VisibilityHighMiles+VisibilityAvgMiles+WindGustMPH+WindHighMPH+WindAvgMPH, data = train.df, family = binomial)
summary(model)
predicted_values <- predict(model, test.df[,-c(1,20,21)], type = "response")
head(predicted_values)
# Validation
table(Rain)
nrows_prediction<-nrow(test.df)
prediction <- data.frame(c(1:nrows_prediction))
colnames(prediction) <- c("Rain")
str(prediction)
prediction$Rain <- as.character(prediction$Rain)
prediction$Rain <- "1"
prediction$Rain[ predicted_values < 0.5] <- "0"
prediction$Rain <- as.factor(prediction$Rain)
#Confusion Matrix
table(prediction$Rain, test.df$Rain)
confusionMatrix(factor(prediction$Rain,levels=min(test.df$Rain):max(test.df$Rain)),
factor(test.df$Rain,levels=min(test.df$Rain):max(test.df$Rain)))
glm.diag.plots(model)
ggplot(test.df, aes(x = test.df$HumidityLowPercent, y = predicted_values))+
geom_point() + # add points
geom_smooth(method = "glm", # plot a regression...
method.args = list(family = "binomial"))
glm.diag.plots(model)
y=glm.diag.plots(model)
y
library(tidyverse)
library(boot)
library(forecast)
library(tseries)
library(caret)
library(ROCR)
library(corrplot)
library(psych)
library(devtools)
library(ggbiplot)
data <- read.csv("C:/Users/Magilan/Desktop/ML_project/austin_weather.csv",header = TRUE)
data1=na.omit(data,invert=FALSE)
attach(data1)
# Principal Component analysis
pc = prcomp(data1[,-c(1,20,21)],
center=TRUE,
scale. = TRUE)
pc$center
pc
summary(pc)
# Orthogonality of PC
windows()
pairs.panels(pc$x,gap=0,pch=21)
gh_install_packages("ggbiplot")
g <- ggbiplot(pc,
obs.scale = 1,
var.scale = 1,
groups = data1$Rain,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)
g <- g + scale_color_continuous(name = '')
g <- g + theme(legend.direction = 'horizontal',
legend.position = 'top')
print(g)
pc.df=data.frame(pc$x)
index <- createDataPartition(Rain, p = 0.7, list = FALSE)
# Training set
train.df <- pc.df[index,]
# Testing dataset
test.df <- pc.df[-index,]
test.Y = data1[-index,21]
model <- lm(data = train.df, Rain ~ .)
summary(model)
predicted_values <- predict(model, test.df[,], type = "response")
head(predicted_values)
#Vlaidation
table(Rain)
nrows_prediction<-nrow(test.df)
prediction <- data.frame(c(1:nrows_prediction))
colnames(prediction) <- c("Rain")
str(prediction)
prediction$Rain <- as.character(prediction$Rain)
prediction$Rain <- "1"
prediction$Rain[ predicted_values < 0.5] <- "0"
prediction$Rain <- as.factor(prediction$Rain)
#Confusion Matrix
table(prediction$Rain, test.Y)
confusionMatrix(factor(prediction$Rain,levels=min(test.Y):max(test.Y)),
factor(test.Y,levels=min(test.Y):max(test.Y)))
#Plotting
glm.diag.plots(model)
ggplot(test.df, aes(x = test.df$HumidityLowPercent, y = predicted_values))+
geom_point() + # add points
geom_smooth(method = "glm", # plot a regression...
method.args = list(family = "binomial"))
library(tidyverse)
library(boot)
library(forecast)
library(tseries)
library(caret)
library(ROCR)
library(corrplot)
library(psych)
library(devtools)
library(ggbiplot)
data <- read.csv("C:/Users/Magilan/Desktop/ML_project/austin_weather.csv",header = TRUE)
data1=na.omit(data,invert=FALSE)
attach(data1)
pc = prcomp(data1[,-c(1,20,21)],
center=TRUE,
scale. = TRUE)
pc.df=data.frame(pc$x)
index <- createDataPartition(Rain, p = 0.7, list = FALSE)
# Training set
train.df <- pc.df[index,]
# Testing dataset
test.df <- pc.df[-index,]
test.Y = data1[-index,21]
model <- lm(data = train.df, Rain ~ .)
summary(model)
model <- lm(Rain ~ . , data = train.df)
train.Y = data1[index,21]
model <- lm(train.Y ~ . , data = train.df)
summary(model)
predicted_values <- predict(model, test.df[,], type = "response")
head(predicted_values)
table(Rain)
nrows_prediction<-nrow(test.df)
prediction <- data.frame(c(1:nrows_prediction))
colnames(prediction) <- c("Rain")
str(prediction)
prediction$Rain <- as.character(prediction$Rain)
prediction$Rain <- "1"
prediction$Rain[ predicted_values < 0.5] <- "0"
prediction$Rain <- as.factor(prediction$Rain)
table(prediction$Rain, test.Y)
confusionMatrix(factor(prediction$Rain,levels=min(test.Y):max(test.Y)),
factor(test.Y,levels=min(test.Y):max(test.Y)))
glm.diag.plots(model)
ggplot(test.df, aes(x = test.df$HumidityLowPercent, y = predicted_values))+
geom_point() + # add points
geom_smooth(method = "glm", # plot a regression...
method.args = list(family = "binomial"))
glm.diag(model)
pl = cbind(tesy.df,test.Y)
pl = cbind(test.df,test.Y)
ggplot(pl, aes(x = test.df$HumidityLowPercent, y = predicted_values))+
geom_point() + # add points
geom_smooth(method = "glm", # plot a regression...
method.args = list(family = "binomial"))
ggplot(pl, aes(x = test.df$PC1, y = predicted_values))+
geom_point() + # add points
geom_smooth(method = "glm", # plot a regression...
method.args = list(family = "binomial"))
ggplot(pl, aes(x = test.df$PC1, y = predicted_values))+
geom_point() + # add points
geom_smooth(method = "glm", # plot a regression...
method.args = list(family = "binomial"))
ggplot(pl, aes(x = data1$HumidityAvgPercent, y = predicted_values))+
geom_point() + # add points
geom_smooth(method = "glm", # plot a regression...
method.args = list(family = "binomial"))
train.df1 <- data1[index,]
test.df1 <- data1[-index,]
ggplot(test.df1, aes(x = test.df1$HumidityAvgPercent, y = predicted_values))+
geom_point() + # add points
geom_smooth(method = "glm", # plot a regression...
method.args = list(family = "binomial"))
ggplot(test.df1, aes(x = test.df1$HumidityLowPercent, y = predicted_values))+
geom_point() + # add points
geom_smooth(method = "glm", # plot a regression...
method.args = list(family = "binomial"))
predicted_values <- predict(model, test.df[,], type = "response")
head(predicted_values)
predicted_values
View(prediction)
ggplot(test.df1, aes(x = test.df1$HumidityLowPercent, y = prediction))+
geom_point() + # add points
geom_smooth(method = "glm", # plot a regression...
method.args = list(family = "binomial"))
ggplot(test.df1, aes(x = test.df1$HumidityLowPercent, y = predicted_values))+
geom_point() + # add points
geom_smooth(method = "glm", # plot a regression...
method.args = list(family = "binomial"))
predicted_values>1
print(if(predicted_values>1)
e
1
s=predicted_values>1
table(s)
model <- glm(train.Y ~ . , data = train.df)
summary(model)
predicted_values <- predict(model, test.df[,], type = "response")
head(predicted_values)
table(Rain)
nrows_prediction<-nrow(test.df)
prediction <- data.frame(c(1:nrows_prediction))
colnames(prediction) <- c("Rain")
str(prediction)
prediction$Rain <- as.character(prediction$Rain)
prediction$Rain <- "1"
prediction$Rain[ predicted_values < 0.5] <- "0"
prediction$Rain <- as.factor(prediction$Rain)
table(prediction$Rain, test.Y)
confusionMatrix(factor(prediction$Rain,levels=min(test.Y):max(test.Y)),
factor(test.Y,levels=min(test.Y):max(test.Y)))
ggplot(test.df1, aes(x = test.df1$HumidityLowPercent, y = predicted_values))+
geom_point() + # add points
geom_smooth(method = "glm", # plot a regression...
method.args = list(family = "binomial"))
s=predicted_values>1
table(s)
View(predicted_values)
model <- glm(train.Y ~ . , data = train.df)
summary(model)
predicted_values <- predict(model, test.df[,c(pc1,pc2,pc3,pc4,pc5,pc6)], type = "response")
tc.df
test.df
model <- glm(train.Y ~ pc1+pc2+pc3+pc4+pc5+pc6 , data = train.df)
summary(model)
model <- glm(train.Y ~ pc1+pc2+pc3+pc4+pc5+pc6 , data = train.df)
summary(model)
names(train.df)
model <- glm(train.Y ~ PC1+PC2+PC3+PC4+PC5+PC6 , data = train.df)
summary(model)
predicted_values <- predict(model, test.df[,c(1,2,3,4,5)], type = "response")
predicted_values <- predict(model, test.df[,c(1,2,3,4,5,6)], type = "response")
head(predicted_values)
table(Rain)
nrows_prediction<-nrow(test.df)
prediction <- data.frame(c(1:nrows_prediction))
colnames(prediction) <- c("Rain")
str(prediction)
prediction$Rain <- as.character(prediction$Rain)
prediction$Rain <- "1"
prediction$Rain[ predicted_values < 0.5] <- "0"
prediction$Rain <- as.factor(prediction$Rain)
table(prediction$Rain, test.Y)
confusionMatrix(factor(prediction$Rain,levels=min(test.Y):max(test.Y)),
factor(test.Y,levels=min(test.Y):max(test.Y)))
library(tidyverse)
library(boot)
library(forecast)
library(tseries)
library(caret)
library(ROCR)
library(corrplot)
library(psych)
library(devtools)
library(ggbiplot)
data <- read.csv("C:/Users/Magilan/Desktop/ML_project/austin_weather.csv",header = TRUE)
data1=na.omit(data,invert=FALSE)
attach(data1)
# Principal Component analysis
pc = prcomp(data1[,-c(1,20,21)],
center=TRUE,
scale. = TRUE)
pc$center
pc
summary(pc)
# Orthogonality of PC
windows()
pairs.panels(pc$x,gap=0,pch=21)
gh_install_packages("ggbiplot")
g <- ggbiplot(pc,
obs.scale = 1,
var.scale = 1,
groups = data1$Rain,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)
g <- g + scale_color_continuous(name = '')
g <- g + theme(legend.direction = 'horizontal',
legend.position = 'top')
print(g)
pc.df=data.frame(pc$x)
index <- createDataPartition(Rain, p = 0.7, list = FALSE)
# Training set
train.df <- pc.df[index,]
train.df1 <- data1[index,]
# Testing dataset
test.df <- pc.df[-index,]
test.df1 <- data1[-index,]
train.Y = data1[index,21]
test.Y = data1[-index,21]
model <- glm(train.Y ~. , data = train.df)
summary(model)
predicted_values <- predict(model, test.df[,], type = "response")
head(predicted_values)
#Vlaidation
table(Rain)
nrows_prediction<-nrow(test.df)
prediction <- data.frame(c(1:nrows_prediction))
colnames(prediction) <- c("Rain")
str(prediction)
prediction$Rain <- as.character(prediction$Rain)
prediction$Rain <- "1"
prediction$Rain[ predicted_values < 0.5] <- "0"
prediction$Rain <- as.factor(prediction$Rain)
#Confusion Matrix
table(prediction$Rain, test.Y)
confusionMatrix(factor(prediction$Rain,levels=min(test.Y):max(test.Y)),
factor(test.Y,levels=min(test.Y):max(test.Y)))
#Plotting
pl = cbind(test.df,test.Y)
ggplot(test.df1, aes(x = test.df1$HumidityLowPercent, y = predicted_values))+
geom_point() + # add points
geom_smooth(method = "glm", # plot a regression...
method.args = list(family = "binomial"))
gh_install_packages("ggbiplot")
library(devtools)
gh_install_packages("ggbiplot")
library(ggbiplot)
g <- ggbiplot(pc,
obs.scale = 1,
var.scale = 1,
groups = data1$Rain,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)
g <- g + scale_color_continuous(name = '')
g <- g + theme(legend.direction = 'horizontal',
legend.position = 'top')
print(g)
library(tidyverse)
library(boot)
library(forecast)
library(tseries)
library(caret)
library(ROCR)
library(corrplot)
library(psych)
library(devtools)
library(ggbiplot)
data <- read.csv("C:/Users/Magilan/Desktop/ML_project/austin_weather.csv",header = TRUE)
data1=na.omit(data,invert=FALSE)
attach(data1)
# Principal Component analysis
pc = prcomp(data1[,-c(1,20,21)],
center=TRUE,
scale. = TRUE)
pc$center
summary(pc)
# Orthogonality of PC
windows()
pairs.panels(pc$x,gap=0,pch=21)
g <- ggbiplot(pc,
obs.scale = 1,
var.scale = 1,
groups = data1$Rain,
ellipse = TRUE,
circle = TRUE,
ellipse.prob = 0.68)
g <- g + scale_color_continuous(name = '')
g <- g + theme(legend.direction = 'horizontal',
legend.position = 'top')
print(g)
pc.df=data.frame(pc$x)
index <- createDataPartition(Rain, p = 0.7, list = FALSE)
# Training set
train.df <- pc.df[index,]
train.df1 <- data1[index,]
# Testing dataset
test.df <- pc.df[-index,]
test.df1 <- data1[-index,]
train.Y = data1[index,21]
test.Y = data1[-index,21]
model <- glm(train.Y ~. , data = train.df)
summary(model)
predicted_values <- predict(model, test.df[,], type = "response")
head(predicted_values)
#Vlaidation
table(Rain)
nrows_prediction<-nrow(test.df)
prediction <- data.frame(c(1:nrows_prediction))
colnames(prediction) <- c("Rain")
str(prediction)
prediction$Rain <- as.character(prediction$Rain)
prediction$Rain <- "1"
prediction$Rain[ predicted_values < 0.5] <- "0"
prediction$Rain <- as.factor(prediction$Rain)
#Confusion Matrix
table(prediction$Rain, test.Y)
confusionMatrix(factor(prediction$Rain,levels=min(test.Y):max(test.Y)),
factor(test.Y,levels=min(test.Y):max(test.Y)))
#Plotting
pl = cbind(test.df,test.Y)
ggplot(test.df1, aes(x = test.df1$HumidityLowPercent, y = predicted_values))+
geom_point() + # add points
geom_smooth(method = "glm", # plot a regression...
method.args = list(family = "binomial"))
windows()
pairs.panels(pc$x,gap=0,pch=21)
pairs.panels(pc$x,gap=0,pch=21)
library(tree)
library(rpart)
library(rpart.plot)
library(caret)
library(bst)
#Data Input
data <- read.csv("D:/STUDY VIT/5th semester/ML_project/austin_weather.csv",header = TRUE)
data1=na.omit(data,invert=FALSE)
attach(data1)
data2=data1[,-c(1,20,22)]
tree.model =tree(Rain ~. , data2,method = "class" )
summary(tree.model)
plot(tree.model )
text(tree.model ,pretty =0)
# Train And Test Data
index <- createDataPartition(Rain, p = 0.7, list = FALSE)
train = data1[index,-c(1,20,22)]
test = data1[-index,-c(1,20,22)]
test.Y = Rain[-index]
# Tree Model
tree.model1 = rpart(Rain ~ . ,data = train, method = "class")
rpart.plot(tree.model1)
plot(tree.model1)
text(tree.model1,pretty = 0)
tree.pred = predict(tree.model1 ,test, type = "class")
table(tree.pred,test.Y)
confusionMatrix(tree.pred,test.Y)
# Cross Validation
model <- train(
Rain ~., data = data1[,-c(1,20,22)], method = "rpart",
trControl = trainControl("cv", number = 10),
preProcess = c("center","scale"),
tuneLength = 20
)
model
plot(model)
ptree<-  prune(tree.model1,cp=0.022303)
rpart.plot(ptree)
plot(ptree)
text(ptree,pretty = 0)
ptree.pred = predict(ptree ,test, type = "class")
table(ptree.pred,test.Y)
confusionMatrix(ptree.pred,test.Y)
# Using Gini Indexing
model1 <- train(
Rain ~., data = data1[,-c(1,20,22)],parms = list(split = "gini"),
method = "rpart",
trControl = trainControl("cv", number = 10),
preProcess = c("center","scale"),
tuneLength = 20
)
plot(model1)
model1$bestTune
tree.pred.gini = predict(model1 ,test)
table(tree.pred.gini,test.Y)
confusionMatrix(tree.pred.gini,test.Y)
library(tree)
library(rpart)
library(rpart.plot)
library(caret)
library(bst)
#Data Input
data <- read.csv("D:/STUDY VIT/5th semester/ML_project/austin_weather.csv",header = TRUE)
data1=na.omit(data,invert=FALSE)
attach(data1)
data <- read.csv("D:/STUDY VIT/5th semester/ML_project/austin_weather.csv",header = TRUE)
